### [Using Synthetic Data to Improve Facial Expression Analysis with 3D Convolutional Networks](http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w23/Abbasnejad_Using_Synthetic_Data_ICCV_2017_paper.pdf)

####  Synthetic Data Generation
##### 1. Face Model
**Shape Modelï¼š**
![shapemodel](https://i.loli.net/2019/01/28/5c4e6c474be97.png)
$U_s$ is the first $n_s$ principal components of PCA

**Texture Model:**
![texture](https://i.loli.net/2019/01/28/5c4e6cd83b1e8.png)

#####2. Expression Model
Each expression can be modeled by manipulating the shape parameters in the face space. Therefore the facial expression can be generated by changing the weights of the $n_s$ PCA components of $U_s$

The optimization problem: To find $p_i$ of Eq.(2) which fit different expression 
![expressionRegistration](https://i.loli.net/2019/01/28/5c4e7ab99c0db.png)

#### Model and Training Method
#####1. Model 
C3D based model
#####2. Training Method
First pre-train the network on the synthetic expressions 
After the pre-training step, fine-tune our network on the real datasets(CK+ and BU-4DFE)

#### Experiment and Evaluation metrics
##### Experiment
1. Action Unit Classification
2. Facial Expression Recognition
##### Two Evaluation metrics
1. Area under ROC Curve
2. $F_1$ score
![f1](https://i.loli.net/2019/01/28/5c4e9bf31e579.png)
